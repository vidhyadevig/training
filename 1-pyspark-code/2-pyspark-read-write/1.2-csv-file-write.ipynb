{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aecf7662-bc66-4fcd-be40-edb76d5af9fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Writing PySpark DataFrame to CSV file\n",
    "**Options** <br>\n",
    "- header: Specifies whether to include a header row with column names in the CSV file. **option(\"header\", \"true\")**\n",
    "- delimiter: Specifies the delimiter to use between fields in the CSV file. **option(\"delimiter\", \",\")**\n",
    "- escape: Specifies the escape character used in the CSV file. **option(\"escape\", \"\\\\\")**\n",
    "- nullValue: Specifies the string to represent null values in the CSV file. **option(\"nullValue\", \"NA\")**\n",
    "- dateFormat: Specifies the date format to use for date columns. **option(\"dateFormat\", \"yyyy-MM-dd\")**\n",
    "- mode: Specifies the write mode for the output. Options include “overwrite”, “append”, “ignore”, and “error”.  **mode(\"overwrite\")** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a5f023a-0426-4513-9a57-3a2380e02047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"/Volumes/workspace/training/test_data/csv\"\n",
    "file_name1 = \"employees.csv\"\n",
    "full_path = f\"{file_path}/{file_name1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ef3710a-9732-4d48-976f-bf3024916849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV File\n",
    "df = spark.read.options(header=True, inferSchema='True',delimiter=',').csv(full_path)\n",
    "filtered_df = df.where(df.age < 30)\n",
    "display(filtered_df)\n",
    "#filtered_df.write.option(\"header\",True).csv(f\"{file_path}/output\")\n",
    "filtered_df.write.mode(\"overwrite\").option(\"header\", True).csv(f\"{file_path}/output\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90bbff95-5c55-43e0-93a6-7a7f2ecf1d90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Saving modes** <br>\n",
    "- overwrite – Overwrite the existing file if already exists.\n",
    "- append – New rows are appended to the existing rows.\n",
    "- ignore – When this option is used, it ignores the writing operation when the file already exists.\n",
    "- error – This option returns an error when the file already exists. This is a default option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd4d571a-95ec-46ee-8b84-3616c2c568aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Using write options\n",
    "\n",
    "filtered_df.write.mode(\"overwrite\").options(header='True', delimiter='|').csv(f\"{file_path}/output\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.2-csv-file-write",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
