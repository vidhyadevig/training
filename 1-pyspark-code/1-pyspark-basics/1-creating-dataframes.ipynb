{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a836d915-adc5-46e7-92ae-80fa36f98507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating DataFrame\n",
    "A DataFrame is a distributed dataset comprising data arranged in rows and columns with named attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc2c4080-e825-421d-85eb-9230578e1979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create DataFrame\n",
    "data = [\n",
    "  ('Aarav', 'Kumar', 'Patel', '1993-08-14', 'M', 5500),\n",
    "  ('Diya', 'Rani', 'Sharma', '1998-03-22', 'F', 6200),\n",
    "  ('Karan', '', 'Mehta', '1985-11-09', 'M', 7200),\n",
    "  ('Isha', 'Vikram', 'Nair', '1990-07-30', 'F', 6800),\n",
    "  ('Rahul', 'Dev', 'Singh', '2001-01-12', 'M', 4800),\n",
    "  ('Priya', '', 'Menon', '1995-05-04', 'F', 7000)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\", \"middlename\", \"lastname\", \"dob\", \"gender\", \"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "# To get the schema of the DataFrame\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56a69649-64c3-4433-9719-0ce3f234b8f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark DataFrame method that prints the data in a tabular text format directly to the console\n",
    "# Shows the 20 rows by default\n",
    "\n",
    "df.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40b542db-c0ae-43ea-b22e-9e9d12d02811",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1761563430762}",
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1761563459045}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks-specific command (not part of PySpark) that shows the DataFrame in an interactive table UI\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae6d6093-cf13-4559-b124-3d353ba1b47c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating dataframes with nested schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac170ff9-5afc-4c09-b024-a0b516948330",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create nested DataFrame data\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "dataDF = [\n",
    "  (('Aarav', 'Kumar', 'Patel'), '1993-08-14', 'M', 5500),\n",
    "  (('Diya', 'Rani', ''), '1998-03-22', 'F', 6200),\n",
    "  (('Karan', '', 'Mehta'), '1985-11-09', 'M', 7200),\n",
    "  (('Isha', 'Vikram', 'Nair'), '1990-07-30', 'F', 6800),\n",
    "  (('Rahul', 'Dev', 'Singh'), '2001-01-12', 'M', 4800)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1-creating-dataframes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
