{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd34f55f-dfe8-4f2b-9b16-4e85dc625aab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###PySpark Read JSON File into DataFrame\n",
    "- Reading JSON File in PySpark\n",
    "- Reading from Multiline JSON File\n",
    "- Reading Multiple Files at a time\n",
    "- Reading all Files in a Folder\n",
    "- Reading files with a user-specified custom schema\n",
    "- Reading file using PySpark SQL\n",
    "\n",
    "Syntax: <br>\n",
    "spark.read.**json**(\"/path/file.json\") <br>\n",
    "spark.read.**format**(\"json\").**load**(\"/path/file.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fd5d27d-490d-48d9-888b-faacab0aa29a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"/Volumes/workspace/training/test_data/json\"\n",
    "file_name1 = \"employee.json\"\n",
    "file_name2 = \"employee_updated1.json\"\n",
    "file_name3 = \"employee_updated2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6199c311-5585-4d84-84d8-2f79339fcef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read JSON file into dataframe\n",
    "full_path = f\"{file_path}/{file_name1}\"\n",
    "df = spark.read.option(\"multiLine\", True).json(full_path)\n",
    "df.printSchema()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15ce2ff-10cf-4bf6-9f8e-74c208900348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read multiple files\n",
    "df = spark.read.option(\"multiLine\", True).json(\n",
    "    [f\"{file_path}/{file_name1}\", f\"{file_path}/{file_name2}\", f\"{file_path}/{file_name3}\"])\n",
    "display(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63dab646-9bd7-4f94-a779-5ec2d6598075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read all JSON files from a folder\n",
    "df = spark.read.options(multiLine=\"true\").json(f\"{file_path}/*.json\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6c95cd4-0570-4e48-b5ec-84211ae502b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading files with a user-specified custom schema\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, DateType\n",
    "\n",
    "employee_schema = StructType([\n",
    "    StructField(\"emp_id\", LongType(), True),\n",
    "    StructField(\"first_name\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"salary\", LongType(), True),\n",
    "    StructField(\"hire_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .schema(employee_schema) \\\n",
    "    .option(\"multiLine\", True) \\\n",
    "    .json(full_path)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d7f0767-2019-47e3-8bc9-6169311f6e71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading File using PySpark SQL\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY VIEW employee\n",
    "    USING json\n",
    "    OPTIONS (path \"{full_path}\", multiLine \"true\")\n",
    "\"\"\")\n",
    "\n",
    "display(spark.sql(\"SELECT * FROM employee\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c57ac6f0-64e5-4f51-8ac2-88a18110d058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reading the json data using SQL syntax by creating temporary view on the dataframe \n",
    "\n",
    "df = spark.read.option(\"multiLine\", True).json(full_path)\n",
    "\n",
    "# Register it as a temporary view\n",
    "df.createOrReplaceTempView(\"vw_employees\")\n",
    "\n",
    "result = spark.sql(\"SELECT emp_id, first_name, salary FROM vw_employees WHERE age < 30\")\n",
    "display(result)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.1-json-read",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
